{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Detection using Deep Learning (Finetuning MobileNet, KERAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required libraries and functions\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from keras import backend\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 321 images belonging to 2 classes.\n",
      "Found 81 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading data and preprocessing images according to mobilenet requirements\n",
    "# Creating batches of data\n",
    "\n",
    "labels = ['Flooding', 'No Flooding']\n",
    "train_path = 'data/train'\n",
    "valid_path = 'data/valid'\n",
    "test_path = 'data/test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=train_path, target_size=(224,224), batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=valid_path, target_size=(224,224), batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=test_path, target_size=(224,224), batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#Loading pre-trained lightweight mobilenet image classifier\n",
    "mobile = tf.keras.applications.mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "# mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'conv_dw_12')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all layers of the original mobilenet except the last 5 layers in variable x\n",
    "# There is no predefined logic behind this, it just gives the optimal results for this task\n",
    "# Also, we will be only training the last 12 layers of the mobilenet during finetuning as we want \n",
    "# it to keep all of the previously learned weights \n",
    "x = mobile.layers[-12].output\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create global pooling, dropout and a binary output layer, as we want our model to be a binary classifier, \n",
    "# i.e. to classify flooding and no flooding\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "output = Dense(units=2, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the new fine-tuned mode\n",
    "model = Model(inputs=mobile.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freez weights of all the layers except for the last five layers in our new model, \n",
    "# meaning that only the last 12 layers of the model will be trained.\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, None, None, 32)    864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, None, None, 32)   128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)   288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, None, None, 32)   128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, None, None, 64)    2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, None, None, 64)   256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)   576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, None, None, 64)   256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, None, None, 128)   8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, None, None, 128)  512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)  1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, None, None, 128)  512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, None, None, 128)   16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, None, None, 128)  512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)  1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, None, None, 128)  512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, None, None, 256)   32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, None, None, 256)  1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)  2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, None, None, 256)  1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, None, None, 256)   65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, None, None, 256)  1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)  2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, None, None, 256)  1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, None, None, 512)   131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)  4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, None, None, 512)   262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)  4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, None, None, 512)   262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)  4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, None, None, 512)   262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, None, None, 512)  2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, None, None, 512)  4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, None, None, 512)  2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, None, None, 512)   262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, None, None, 512)  2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, None, None, 512)  4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, None, None, 512)  2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, None, None, 512)   262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, None, None, 512)  2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)  0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, None, None, 512)  4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,633,474\n",
      "Trainable params: 812,034\n",
      "Non-trainable params: 821,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohail\\.conda\\envs\\python_3_gpss\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohail\\.conda\\envs\\python_3_gpss\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 - 7s - loss: 1.1020 - accuracy: 0.6449 - val_loss: 0.1976 - val_accuracy: 0.9012 - 7s/epoch - 198ms/step\n",
      "Epoch 2/10\n",
      "33/33 - 5s - loss: 0.6148 - accuracy: 0.8442 - val_loss: 0.1322 - val_accuracy: 0.9506 - 5s/epoch - 143ms/step\n",
      "Epoch 3/10\n",
      "33/33 - 5s - loss: 0.3302 - accuracy: 0.8847 - val_loss: 0.1181 - val_accuracy: 0.9506 - 5s/epoch - 144ms/step\n",
      "Epoch 4/10\n",
      "33/33 - 5s - loss: 0.3077 - accuracy: 0.9097 - val_loss: 0.1165 - val_accuracy: 0.9383 - 5s/epoch - 149ms/step\n",
      "Epoch 5/10\n",
      "33/33 - 5s - loss: 0.2059 - accuracy: 0.9346 - val_loss: 0.0990 - val_accuracy: 0.9506 - 5s/epoch - 146ms/step\n",
      "Epoch 6/10\n",
      "33/33 - 5s - loss: 0.2501 - accuracy: 0.9283 - val_loss: 0.0753 - val_accuracy: 0.9630 - 5s/epoch - 151ms/step\n",
      "Epoch 7/10\n",
      "33/33 - 5s - loss: 0.1502 - accuracy: 0.9564 - val_loss: 0.0693 - val_accuracy: 0.9753 - 5s/epoch - 154ms/step\n",
      "Epoch 8/10\n",
      "33/33 - 5s - loss: 0.1493 - accuracy: 0.9439 - val_loss: 0.0523 - val_accuracy: 0.9753 - 5s/epoch - 151ms/step\n",
      "Epoch 9/10\n",
      "33/33 - 5s - loss: 0.1356 - accuracy: 0.9595 - val_loss: 0.0419 - val_accuracy: 0.9877 - 5s/epoch - 149ms/step\n",
      "Epoch 10/10\n",
      "33/33 - 5s - loss: 0.1243 - accuracy: 0.9564 - val_loss: 0.0583 - val_accuracy: 0.9753 - 5s/epoch - 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1492a4e6d60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "          steps_per_epoch=len(train_batches),\n",
    "          validation_data=valid_batches,\n",
    "          validation_steps=len(valid_batches),\n",
    "          epochs=10,\n",
    "          verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading our trained for future use\n",
    "\n",
    "model.save(\"fine_tuned_flood_detection_model\")\n",
    "# model.load_weights('fine_tuned_flood_detection_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and plot confusion matrix to look how well our model performed in classifying \n",
    "# flooding and no flooding images \n",
    "\n",
    "test_labels = test_batches.classes\n",
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "precision = precision_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "f1_score = f1_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "accuracy = accuracy_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pring precision, F1 score and accuracy of our model\n",
    "print('Precision: ', precision)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix \n",
    "test_batches.class_indices\n",
    "cm_plot_labels = ['Flooding','No Flooding']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for mobilenet prediction\n",
    "\n",
    "def preprocess_image(file):\n",
    "    img_path = 'evaluate/'\n",
    "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image which we want to predict\n",
    "from IPython.display import Image\n",
    "Image(filename='evaluate/1.jpg', width=300,height=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess image and make prediction\n",
    "\n",
    "preprocessed_image = preprocess_image('1.jpg')\n",
    "predictions = model.predict(preprocessed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predicted accuracy scores for both classes, i.e. (1) Flooding, (2) No Flooding\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum probability score for predicted class from predictions array\n",
    "result = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted class label\n",
    "labels[result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE, This code was inspired and modified from the following source: \n",
    "https://deeplizard.com/.\n",
    "\n",
    "\n",
    "Flooding images were collected from paper named \"Detecting floodwater on roadways from image data with handcrafted features and deep transfer learning*\", available at \"https://arxiv.org/pdf/1909.00125.pdf\". \n",
    "\n",
    "Funfact: This model outperforms the model presented in the paper.\n",
    "\n",
    "Normal or No Flooding images were collected from google image search, there may be irrelevant images in this category\n",
    "because the images were downloaded using an automated script. \n",
    "\n",
    "The trained model performed quite impressively and got an accuracy score of over 98%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
